{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "from convnet import DiscriminatorConvNet, GeneratorConvNet\n",
    "from resnet import DiscriminatorResNet, GeneratorResNet\n",
    "from utils import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAINING HYPERPARAMETERS\n",
    "\n",
    "Directly taken from paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_seed = 999\n",
    "\n",
    "num_gpu = 1\n",
    "lr = 1e-4\n",
    "beta1 = 0\n",
    "beta2 = 0.9\n",
    "num_epochs = 50\n",
    "\n",
    "dataroot=\"../data\"\n",
    "batch_size=64\n",
    "workers = 4\n",
    "image_size=48\n",
    "\n",
    "real_label = 1\n",
    "fake_label = -1\n",
    "\n",
    "random.seed(manual_seed)\n",
    "torch.manual_seed(manual_seed)\n",
    "\n",
    "# Look for available GPU(s)\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and num_gpu > 0) else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sphere-GAN CONVNET Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DiscriminatorConvNet(\n",
       "  (conv1_1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (ln1_1): LayerNorm(torch.Size([64, 48, 48]), eps=1e-05, elementwise_affine=True)\n",
       "  (lrelu1_1): LeakyReLU(negative_slope=0.2, inplace)\n",
       "  (conv1_2): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (ln1_2): LayerNorm(torch.Size([64, 24, 24]), eps=1e-05, elementwise_affine=True)\n",
       "  (lrelu1_2): LeakyReLU(negative_slope=0.2, inplace)\n",
       "  (conv2_1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (ln2_1): LayerNorm(torch.Size([128, 24, 24]), eps=1e-05, elementwise_affine=True)\n",
       "  (lrelu2_1): LeakyReLU(negative_slope=0.2, inplace)\n",
       "  (conv2_2): Conv2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (ln2_2): LayerNorm(torch.Size([128, 12, 12]), eps=1e-05, elementwise_affine=True)\n",
       "  (lrelu2_2): LeakyReLU(negative_slope=0.2, inplace)\n",
       "  (conv3_1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (ln3_1): LayerNorm(torch.Size([256, 12, 12]), eps=1e-05, elementwise_affine=True)\n",
       "  (lrelu3_1): LeakyReLU(negative_slope=0.2, inplace)\n",
       "  (conv3_2): Conv2d(256, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (ln3_2): LayerNorm(torch.Size([256, 6, 6]), eps=1e-05, elementwise_affine=True)\n",
       "  (lrelu3_2): LeakyReLU(negative_slope=0.2, inplace)\n",
       "  (conv4): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (gb): GeometricBlock(\n",
       "    (ln): Linear(in_features=512, out_features=1024, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "genConv = GeneratorConvNet()\n",
    "disConv = DiscriminatorConvNet()\n",
    "\n",
    "genConv.apply(weights_init)\n",
    "disConv.apply(weights_init)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "optimizerG = optim.Adam(genConv.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "optimizerD = optim.Adam(disConv.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "\n",
    "# Create batch of latent vectors that we will use to visualize\n",
    "#  the progression of the generator\n",
    "fixed_noise = torch.randn(64, 128, 1, 1, device=device)\n",
    "dataloader = get_stl10_dataloader(dataroot, batch_size, workers, image_size)\n",
    "\n",
    "img_list = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "iters = 0\n",
    "moments = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1024]) torch.Size([64, 1])\n",
      "torch.Size([64, 1025])\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-69ce7bd6323f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# Calculate loss on all-real batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0merror_disc_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_moment_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmoments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# Calculate gradients for D in backward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dl/ceng796/sphere_gan/utils.py\u001b[0m in \u001b[0;36mtotal_moment_distance\u001b[0;34m(output, target, moments, device)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;31m#print(target.size(), output.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mdistance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmoments\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m                 \u001b[0mdistance\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mget_distance_to_north_pole\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "# For each epoch\n",
    "for epoch in range(num_epochs):\n",
    "    # For each batch in the dataloader\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "\n",
    "        ############################\n",
    "        # (1) Update Discriminator\n",
    "        ###########################\n",
    "        disConv.zero_grad()\n",
    "        label = torch.full((batch_size,), real_label, device=device)\n",
    "        \n",
    "        # Forward pass real batch through D\n",
    "        output = disConv(data[0])\n",
    "        print(output.size())\n",
    "        \n",
    "        # Calculate loss on all-real batch\n",
    "        error_disc_real = total_moment_distance(output, label, moments, device)\n",
    "        \n",
    "        # Calculate gradients for D in backward pass\n",
    "        error_disc_real.backward()\n",
    "\n",
    "        ## Train with all-fake batch\n",
    "        \n",
    "        # Generate batch of latent vectors\n",
    "        noise = torch.randn(batch_size, 128, 1, 1, device=device)\n",
    "        \n",
    "        # Generate fake image batch with G\n",
    "        fake = genConv(noise)\n",
    "        label.fill_(fake_label)\n",
    "        \n",
    "        # Classify all fake batch with D\n",
    "        output = netD(fake.detach())\n",
    "        \n",
    "        # Calculate D's loss on the all-fake batch\n",
    "        error_disc_fake = total_moment_distance(output, label, moments, device)\n",
    "        \n",
    "        # Calculate the gradients for this batch\n",
    "        error_disc_fake.backward()\n",
    "\n",
    "        # Add the gradients from the all-real and all-fake batches\n",
    "        error_disc = error_disc_real + error_disc_fake\n",
    "        \n",
    "        # Update D\n",
    "        optimizerD.step()\n",
    "\n",
    "        ############################\n",
    "        # (2) Update Generator\n",
    "        ###########################\n",
    "        genConv.zero_grad()\n",
    "        \n",
    "        label.fill_(real_label)  # fake labels are real for generator cost\n",
    "        \n",
    "        # Since we just updated D, perform another forward pass of all-fake batch through D\n",
    "        output = disConv(fake)\n",
    "        \n",
    "        # Calculate G's loss based on this output\n",
    "        error_gen = total_moment_distance(output, label, device)\n",
    "        \n",
    "        # Calculate gradients for G\n",
    "        error_gen.backward()\n",
    "        \n",
    "        # Update G\n",
    "        optimizerG.step()\n",
    "\n",
    "        # Output training stats\n",
    "        if i % 50 == 0:\n",
    "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
    "                  % (epoch, num_epochs, i, len(dataloader),\n",
    "                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
    "\n",
    "        # Save Losses for plotting later\n",
    "        G_losses.append(error_gen.item())\n",
    "        D_losses.append(error_disc.item())\n",
    "\n",
    "        # Check how the generator is doing by saving G's output on fixed_noise\n",
    "        if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(dataloader)-1)):\n",
    "            with torch.no_grad():\n",
    "                fake = netG(fixed_noise).detach().cpu()\n",
    "            img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
    "\n",
    "        iters += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p3-dl-venv",
   "language": "python",
   "name": "p3-dl-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
